
<!DOCTYPE html>
<html>
  <head>
    <title>Tokenizer</title>
  </head>
  <body>
  <script>

  var Tokenizer = function(str) {
    // Private
    var lexemes = str.split(/[" "]/);
    var index = 0;

    // Public
    var peek = function() {
      if (index >= lexemes.length) return { type: "EOF", val: "" };

      var lexeme = lexemes[index];
      var c = lexeme.charAt(0);

      if      (c == '&') token = { type: "AND"   , val: "&"    } ;
      else if (c == '|') token = { type: "OR"    , val: "|"    } ;
      else if (c == '(') token = { type: "OPEN"  , val: "("    } ;
      else if (c == ')') token = { type: "CLOSE" , val: ")"    } ;
      else               token = { type: "STR"   , val: lexeme } ;

      return token;
    }

    var get = function() {
      token = peek();
      if (token.type != "EOF") index++;

      return token;
    }

    getStr = function() { return str; }

    return {
      peek   : peek,
      get    : get,
      getStr : getStr
    }
  }

  function dump(tokenizer) {
    for(token = tokenizer.get(); token.type != "EOF"; token = tokenizer.get()) {
      console.log("type: ", token.type, " value: ", token.val);
    }
  }

  var Token = function(type, val) {
    console.log("Token -> type: " + type + " val: " + val);
    return {
      type    : type,
      val     : val,
      toString: function() { return "type: " + this.type + " val: " + this.val; }
    };

    return token;
  }

  function getc() {
    if (index < str.length) {
      var c = str.charAt(index);

      index++;

      return c;
    }

    return false;
  }

  function ungetc() {
    index--;
  }

  function get() {
    var lexeme = "";
    var isOp   = function(c) { return c.match(/[ &|)]/); }
    var isText = function(c) { return !isOp(c); }
    var c, nextc;
    var token, type, val;

    c = getc();
    if (!c) return new Token("EOF", "EOF");

    val = c;
    console.log("val: " + c);
    if (isText(c)) {
      while((c = getc()) && isText(c)) {
        val += c;
        console.log("val: " + val);
      }
      if (c) ungetc();

      console.log("creating Token: " + val);
      return new Token("STR", val);
    }

//    switch(c) {
//      case ' ':
//        nextc = getc();
//
//        if (!nextc) {
//          token = new Token("EOF", "EOF");
//        } else if (isOp(nextc)) {
//          token = new Token(nextc, nextc);
//
//          while((nextc = getc()) && isOp(nextc));
//          if (nextc) ungetc();
//        } else {
//        }
//    }
//
//    if (isOp(c)) {
//      return new Token(c);
//    }
//    else {
//      lexeme += c;
//      while((c = getc())) {
//        if (!isOp(c) lexeme += c;
//      }
//
//      return new Token(lexeme);
//    }
  }

  str = "(this is a token &another token)"
  index = 0;

  var token = get();
  console.log("get: " + token);

//  function testToken(lexeme) {
//    token = new Token(lexeme);
//    console.log("token: " + token);
//  }

//  testToken("&");
//  testToken("|");
//  testToken(")");
//  testToken("coriolanus");

//  function testGetchar(str) {
//    var c;
//
//    console.log(str);
//
//    while((c = getchar())) {
//      console.log("index: " + index + " char: [" + c + "]");
//    }
//  }

//  testGetchar("this is a long string & |");

//  var shakespeare = new Tokenizer("to be or & not to | be");
//  var auden       = new Tokenizer("perfection of & a kind was | what he was after");
//
//  dump(shakespeare);
//  console.log("================");
//  dump(auden);


  </script>
  </body>
</html>
